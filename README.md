# Introduction

The purpose of this project was to implement a working client and server that interacted with each other. The client must interact with the user to receive commands and process these requests by a multithreaded implementation where all the requests are sent to the server as soon as they are ready. The server handles the requests iteratively, executes the specified tasks, and returns the requested data to the client. This paper will discuss the design and implementation of both the client and the server. Each client request was performed for 1, 5, 10, 15, 20, and 25 times and the elapsed time for the data to be sent from the client to the server and to return was recorded. This paper covers the data collection and analysis.

# Client-Server Setup and Configuration

After the client and server begin running, the user will be prompted to input the IP address and the port number by the client and to input just the port number on the server. Then, the client prompts the user with a menu to choose from the functions it can perform, including Date and Time, Uptime, Memory Use, Netstat, Current Users, and Running Processes. After the choice is made, the client will prompt the user with how many requests are to be sent to the server. 
The multithreading of the client is created in a class called “ClientConnection.” A new ClientConnection object is created for each request. Within ClientConnection, the socket that connects the server and the client is created, meaning a new socket is created for each request and is closed once the request is completed. 
Like the client, the server also uses the Thread class. Unlike the client, the server handles each request from the client iteratively. The server listens for requests from the client and cycles through a while loop so long as the thread of the server is still alive. When the server receives a request, it connects to the client and then processes the client’s request and returns the data to the client before closing the connection. The client then prints the elapsed time for each request and then the total elapsed time of all the requests and the average elapsed time per request. The client and server will repeat these steps until the user exits the menu. 
Our first notable design choice was that we created a JavaServer object to handle the server and multiple ClientConnection objects to handle the client. Another notable design choice was the specific design of the server sending data to the client and how the client received it. The server reads input from the Linux commands and appends all the data into one long string and sends that string to the client. The client reads the data from the server in a do…while loop using the DataInputStream function “.available()”. This function was the solution of a major problem, as will be discussed in the conclusion.

# Testing and Data Collection

To test the total turn-around time of the Iterative Socket Server, we asked the client to generate 1, 5, 10, 15, 20, and 25 requests to the server for each available command. The total and average elapsed times of each request is recorded in the table below and for clarity we have graphed the total elapsed time by number of requests and the average elapsed time by number of requests. Looking at the total time in microseconds graph we see that the Date and Time remains constant as the number of threads increases. The Date and Time requests take a constant amount of time, probably because this is the only request that does not execute a Linux command, but simply creates an object using the Date class. The Running Processes and Current Users commands begin to increase in time more drastically after 20 requests are made. As the number of clients increases, the time to run Netstat, Uptime, and Memory Use all slowly increase.
By looking at the average time in microseconds graph we find more helpful data. We can see that as the number of requests increases, the average time spent executing these requests also increases following a linear path. This changes after 20 requests are made. The time spent on Running Processes and Current Users increases more dramatically, while Netstat, Uptime, and Memory Use all plateau. The average time of Memory Use indicates that there is a certain amount of overhead in executing that function. Executing only one request took almost the same time as it took to execute five of the same requests. As Memory Use, Netstat, and Uptime all reach more than 20 requests, the individual requests are more efficient. While the total time increases as the number of requests increases, average time per request remains constant in those three cases.





# Conclusion and Lessons Learned

From the data, we can hypothesize that the client requests that require the server to execute Linux commands require a certain amount of overhead and each function has a pivotal number where adding more requests will negligibly affect the time spent per request. Whether we are shopping at Costco or sending client requests, it is cheaper to buy in bulk. The two functions that were exceptions to this hypothesis, Current Users and Running Processes, beg the question to if they are exceptions, or if they require more overhead. Perhaps if we had run 50 client requests, we would see Current Users and Running Processes begin to plateau like the other functions. However, this is only speculation, and any conclusions drawn on this data are dubious at best as each test with the two variables (function call and amount of threads) was only performed once. 
We learned many lessons while implementing the Iterative Socket Server. The understanding of multithreading and iterative threading and how to make them interact properly was a major part of our project. As Professor Kelly knows, we had trouble with the client being unable to consistently read the data from the server. Our original code had a while loop in the client that read the information from the server until it read a null. In our code, this while loop would run infinitely. According to Professor Kelly and the examples he provided, this while loop was used in many successful projects, but not ours. After many hours of edits on edits with no progress, we eventually just scratched most of our server and built it again. During this time, we learned about many functions and aspects of client-server relations as we tried to solve our problem with anything we could find. The key differences in our working code and our original code on the server side is that our final server explicitly implements Runnable and thus has a Thread that we could ensure was iterative. On the client side, instead of reading the data from the server until “readline() == null” we read input from the server while “.available() > 0.” With this function, our problem while loop no longer ran infinitely. 
Two other features that were learned during this project were “synchronize()” and “CountDownLatch.” The synchronize() function finally gave us the handle on our iterative server that we needed. Before this function, the multithreaded client was printing its results as soon as it received it, which meant that multiple results were printing simultaneously. This was ugly and unhelpful to the user viewing the client. Adding “syncronize()” to the server thread made sure the server was not handling multiple threads at once, so the output became much nicer to view. The use of CountDownLatch was a purely cosmetic add. Before researching CountDownLatch and implementing it, our client menu would print regardless of if the requests were done printing. CountDownLatch enabled us to have the menu prompting the user wait until all the requests had finished. 

